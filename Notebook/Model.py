# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gGC-yVnpsKZ5dDvn_dg6SDdJC9RNmWfK

# Submission Pertama: Menyelesaikan Permasalahan Human Resources

- Nama: Hafiizh Taufiqul Hakim
- Email: 2012500720@student.budiluhur.ac.id
- Id Dicoding: hafizhtaufiqul1002

# Persiapan

### Menyiapkan library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
# Manipulasi Data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
# %matplotlib inline
import seaborn as sns
import os

# Preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from imblearn.over_sampling import SMOTE, RandomOverSampler
from sklearn.model_selection import train_test_split

# Model
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import GaussianNB

# Evaluasi
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score

# Save Model
import pickle

import warnings
warnings.filterwarnings('ignore')

"""### Menyiapkan data yang akan digunakan"""

# import dataset
dataset = "https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/employee/employee_data.csv"

"""Dataset yang digunakan pada proyek ini adalah **employee_data.csv** yang bersumber dari github Dicoding

# Data Understanding

Adapun kolom-kolom yang terdapat pada dataset sebagai berikut :

- EmployeeId - ID Karyawan.
- Attrition - Apakah terjadi pengurangan karyawan? (0 = tidak, 1 = ya).
- Age - Usia karyawan.
- BusinessTravel - Komitmen perjalanan untuk pekerjaan.
- DailyRate - Gaji harian.
- Department - Departemen Karyawan.
- DistanceFromHome - Jarak dari tempat kerja ke rumah (dalam km).
- Education - 1-Sekolah Menengah Pertama, 2-Sekolah Menengah Atas, 3-Sarjana, 4-Sarjana, 5-Doktor.
- EducationField - Bidang Pendidikan.
- EnvironmentSatisfaction - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi.
- Gender - Jenis kelamin karyawan.
- HourlyRate - Gaji per jam.
- JobInvolvement - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi.
- JobLevel - Tingkat pekerjaan (1 hingga 5).
- JobRole - Peran Pekerjaan.
- JobSatisfaction - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi.
- MaritalStatus - Status Pernikahan.
- MonthlyIncome - Gaji bulanan.
- MonthlyRate - Tarif per bulan.
- NumCompaniesWorked - Jumlah perusahaan tempat bekerja.
- Over18 - Berusia di atas 18 tahun?.
- OverTime - lembur?.
- PercentSalaryHike - Persentase kenaikan gaji tahun lalu.
- PerformanceRating - 1-Rendah, 2-Baik, 3-SangatBaik, 4-LuarBiasa.
- RelationshipSatisfaction - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi.
- StandardHours - Jam Standar.
- StockOptionLevel - Tingkat Opsi Saham.
- TotalWorkingYears - Total tahun bekerja.
- TrainingTimesLastYear - Jumlah pelatihan yang diikuti tahun lalu.
- WorkLifeBalance - 1-Rendah, 2-Baik, 3-Sangat Baik, 4-Sangat Baik.
- YearsAtCompany - Tahun di Perusahaan.
- YearsInCurrentRole - Tahun dalam peran saat ini.
- YearsSinceLastPromotion - Tahun sejak promosi terakhir.
- YearsWithCurrManager - Tahun dengan manajer saat ini.

# Data Preparation

##### Gathering data
"""

df = pd.read_csv(dataset)
df.sample(5).T

"""##### Asessing Data"""

# Cek Tipe Data
df.info()

"""Seluruh tipe data sudah sesuai, tetapi ada satu fitur di mana tipe data pada kolom Attrition akan diubah menjadi int."""

num = df.select_dtypes(exclude='object').columns
cat = df.select_dtypes(include='object').columns

print("Jumlah data numerik:", len(num))
print("Jumlah data kategorik:", len(cat))

# Cek Missing Value
df.isna().sum()

"""Terdapat missing value pada kolom Attrition, Sehingga perlu dilakukan penanganan terhadap kolom yang terdapat missing value"""

# Cek Duplicated
df.duplicated().sum()

"""Tidak terdapat duplikasi pada dataset"""

# kolom Attrition
df.Attrition.value_counts()

# kolom EmployeeCount
df.EmployeeCount.value_counts()

# kolom Over18
df.Over18.value_counts()

df.StandardHours.value_counts()

# Cek Outlier
print(f'Jumlah baris: {len(df)}')

outlier = []
no_outlier = []
is_outlier = []
low_lim = []
high_lim = []


filtered_entries = np.array([True] * len(df))
for col in num:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    low_limit = Q1 - (IQR * 1.5)
    high_limit = Q3 + (IQR * 1.5)

    #mulai filter outlier
    filter_outlier = ((df[col] >= low_limit) & (df[col] <= high_limit))
    outlier.append(len(df[~filter_outlier]))
    no_outlier.append(len(df[filter_outlier]))
    is_outlier.append(df[col][~filter_outlier].any())
    low_lim.append(low_limit)
    high_lim.append(high_limit)

    filtered_entries = ((df[col] >= low_limit) & (df[col] <= high_limit)) & filtered_entries

print("Outlier All Data :", len(df[~filtered_entries]))
print("Not Outlier All Data :", len(df[filtered_entries]))
print()

pd.DataFrame({
    "Column Name":num,
    "is Outlier": is_outlier,
    "Lower Limit": low_lim,
    "Upper Limit": high_lim,
    "Outlier":outlier,
    "No Outlier":no_outlier
})

"""Ada beberapa data yang menunjukkan adanya outliers. Sehingga, perlu melakukan penanganan lebih lanjut dengan menggunakan metode IQR untuk mengatasi masalah ini.

##### Data Cleaning
"""

df_clean = df.copy()

df_clean = df_clean.drop(['EmployeeId', 'EmployeeCount', 'Over18', 'StandardHours'], axis=1)

"""Menghapus beberapa kolom karena hanya memiliki 1 nilai saja dan kolom ID"""

# Handle Missing Value
df_clean.dropna(axis=0, inplace=True)
df_clean.isna().sum()

"""Melakukan penanganan terhadap kolom yang mengalami missing value dengan cara menghapus nilai yang kosong."""

# Merubah Tipe data Attrition ke int
df_clean["Attrition"] = df_clean["Attrition"].astype(int)

"""Merubah tipe data float menjadi integer pada kolom Attrition"""

# Handle Outliers
num = df_clean.select_dtypes(exclude='object').columns

outlier_columns = []

for col in num:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1

    outlier_step = 1.5 * IQR
    outlier_list_col = df_clean[(df_clean[col] < Q1 - outlier_step) | (df_clean[col] > Q3 + outlier_step)].index

    if outlier_list_col.any():
        outlier_columns.append(col)

print("Jumlah Kolom:", len(df_clean.columns))
print("Jumlah Kolom Outliers:", len(outlier_columns))

is_outlier = df_clean[outlier_columns].drop(['Attrition', 'PerformanceRating'], axis=1)

print('Jumlah baris sebelum handle outlier :', df_clean.shape[0])
# Iterasi melalui setiap kolom untuk menangani outlier
for column in is_outlier:
    Q1 = df_clean[column].quantile(0.25)
    Q3 = df_clean[column].quantile(0.75)
    IQR = Q3 - Q1

    # Menghitung batas bawah dan atas outlier
    lower_limit = Q1 - (1.5 * IQR)
    upper_limit = Q3 + (1.5 * IQR)

    # Menghapus outlier dari DataFrame
    df_outliers = df_clean[(df_clean[column] >= lower_limit) & (df_clean[column] <= upper_limit)]

print('Jumlah baris setelah handle outlier :', df_outliers.shape[0])

"""### Data Transformation

##### Data Untuk Visualisasi
"""

df_visualisasi = df_clean.copy()

# Mengubah label pada kolom numerik
def label_column(fitur):
    if fitur == "Attrition":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "Karyawan Beratahan" if x == 0 else "Karyawan Keluar")
    elif fitur == "JobLevel":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "Basic" if x == 1 and 2 else "Intermediate " if x == 3 and 4 else "Advanced")
    elif fitur == "Education":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "Below College" if x == 1 else "College" if x == 2 else "Bachelor" if x == 3 else "Master" if x == 4 else "Doctor")
    elif fitur == "WorkLifeBalance":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "Low" if x == 1 else "Good" if x == 2 else "Excellent" if x == 3 else "Outstanding")
    elif fitur == "YearsAtCompany":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "0-5 years" if x <=5 else "6-10 years" if x <=10 else "11-20 years" if x <=20 else "> 20 years")
    elif fitur == "YearsWithCurrManager":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "0-5 years" if x <=5 else "6-10 years" if x <=10 else "11-20 years" if x <=20 else "> 20 years")
    elif fitur == "DistanceFromHome":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "0-5 km" if x <=5 else "6-10 km" if x <=10 else "11-15 km" if x <=15 else "16-20 km" if x <=20 else "> 20 km")
    elif fitur == "PercentSalaryHike":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "< 15%" if x <=15 else "20%" if x <=20 else "25%")
    elif fitur == "Age":
        df_visualisasi[fitur] = df_visualisasi[fitur].apply(lambda x: "< 25" if x <=25 else "26-30" if x <=30 else "31-35" if x <=35 else "36-40" if x <=40 else "41-45" if x <=45 else "46-50" if x <=50 else "> 60")
    else:
        for col in fitur:
            df_visualisasi[col] = df_visualisasi[col].apply(lambda x: "Low" if x == 1 else "Medium" if x == 2 else "High" if x == 3 else "Very High")
    return df_visualisasi

fitur1 = "Attrition"
df_visualisasi = label_column(fitur1)

fitur2 = "JobLevel"
df_visualisasi = label_column(fitur2)

fitur3 = "Education"
df_visualisasi = label_column(fitur3)

fitur4 = "WorkLifeBalance"
df_visualisasi = label_column(fitur4)

fitur5 = "YearsAtCompany"
df_visualisasi = label_column(fitur5)

fitur6 = "YearsWithCurrManager"
df_visualisasi = label_column(fitur6)

fitur7 = "DistanceFromHome"
df_visualisasi = label_column(fitur7)

fitur8 = "PercentSalaryHike"
df_visualisasi = label_column(fitur8)

fitur9 = "Age"
df_visualisasi = label_column(fitur9)

fitur10 = ["EnvironmentSatisfaction", "JobInvolvement", "StockOptionLevel",
          "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction"]
df_visualisasi = label_column(fitur10)

"""Pada tahap ini, Beberapa data numerik diubah menjadi kategorik dengan pemberian label, Sehingga datanya dapat digunakan untuk pembuatan visualisasi data dan mempermudah analisis data.   
\
Adapun kolom yang diubah sebagai berikut:  
- Attrition
- JobLevel
- Education
- WorkLifeBalance
- EnvironmentSatisfaction
- JobInvolvement
- StockOptionLevel
- JobSatisfaction
- PerformanceRating
- RelationshipSatisfaction

##### Label Encoding
"""

df_encoding = df_clean.copy()

cat = df_encoding.select_dtypes(include='object').columns

df_encoding[cat].describe()

df_encoding.EducationField.value_counts()

df_encoding.JobRole.value_counts()

label_encoder = LabelEncoder()

is_label_encoding = df_encoding[cat].columns

for col in is_label_encoding:
      df_encoding[col] = label_encoder.fit_transform(df_encoding[col])

df_encoding.info()

"""Melakukan **Label Encoding** dan **One Hot Encoding** bertujuan untuk mengubah data kategorik menjadi numerik. Sehingga data dapat di normalisasi dan di standarisasi.

### Drop Fitur
"""

df_model = df_encoding.copy()

corr = df_model.corr()
plt.figure(figsize=(20, 20))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap', fontsize=16, fontweight='bold')
plt.xticks(rotation=90, fontsize=16)
plt.yticks(rotation=0, fontsize=16)
plt.show()

drop_col = ['BusinessTravel', 'DailyRate', 'HourlyRate','DistanceFromHome', 'JobSatisfaction',
            'OverTime', 'PercentSalaryHike', 'StockOptionLevel', 'NumCompaniesWorked',
            'TrainingTimesLastYear', 'YearsSinceLastPromotion', 'YearsInCurrentRole',
            'YearsWithCurrManager', 'MonthlyRate',]

df_model = df_model.drop(drop_col, axis=1)

df_model.columns

"""### Split Dataset"""

X = df_model.drop(columns="Attrition")
y = df_model["Attrition"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training :", X_train.shape)
print("Testing :", X_test.shape)

"""### Feature Scaling

##### Standarisasi
"""

# Melakukan Standarisasi untuk beberapa fitur
std_scaler = StandardScaler()
X_train = std_scaler.fit_transform(X_train)

X_train

"""Pada tahap ini, Beberapa fitur akan dilakukan standarisasi. Hal ini dilakukan agar data dapat digunakan untuk proses pemodelan.

# Modeling
"""

# Selection model
models = {}

# Logistic Regression
models['Logistic Regression'] = LogisticRegression(random_state=42)

# Decision Trees
models['Decision Trees'] = DecisionTreeClassifier(random_state=42)

# Random Forest
models['Random Forest'] = RandomForestClassifier(random_state=42)

# XGBoost
models['XGBoost'] = XGBClassifier(random_state=42)

# Naive Bayes
models['Naive Bayes'] = GaussianNB()

accuracy, precision, recall, f1, roc_auc = {}, {}, {}, {}, {}

for key in models.keys():
    # Melakukan train setiap model
    models[key].fit(X_train, y_train)

    # Melakukan prediksi model
    predict = models[key].predict(X_test)

    # Menghitung metrik Accuracy, Precision and Recall
    accuracy[key] = accuracy_score(y_test, predict)
    precision[key] = precision_score(y_test, predict)
    recall[key] = recall_score(y_test, predict)
    f1[key] = f1_score(y_test, predict)
    roc_auc[key] = roc_auc_score(y_test, predict)

# Menampilkan evaluasi setiap model
df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Roc_Auc'])
df_model['Accuracy'] = accuracy.values()
df_model['Precision'] = precision.values()
df_model['Recall'] = recall.values()
df_model['F1-Score'] = f1.values()
df_model['Roc_Auc'] = roc_auc.values()

round(df_model, 2)

"""# Evaluasi"""

oversampler = RandomOverSampler(random_state=42)
X_resampled, y_resampled = oversampler.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""### Cross Validation"""

for name, model in models.items():
    # Cross validation score
    y_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='f1')

    # cetak rata-rata skor
    print(f"Rata-rata skor {name}:", round(np.mean(y_scores), 2))

"""### Confusion Matriks"""

models = {}

# Logistic Regression
models['Logistic Regression'] = LogisticRegression(random_state=42)

# Decision Trees
models['Decision Trees'] = DecisionTreeClassifier(random_state=42)

# Random Forest
models['Random Forest'] = RandomForestClassifier(random_state=42)

# XGBoost
models['XGBoost'] = XGBClassifier(random_state=42)

# Naive Bayes
models['Naive Bayes'] = GaussianNB()

best_model = None
best_accuracy = 0

for name, model in models.items():
    # Melakukan train setiap model
    model.fit(X_train, y_train)

    # Melakukan prediksi model
    predict = model.predict(X_test)

    # Best Model
    accuracy = accuracy_score(y_test, predict)
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = model

    # Classification Report
    print(f"Classification Report model {name}:")
    print(classification_report(y_test, predict))

    # Confusion Matrix
    cm = confusion_matrix(y_test, predict)
    plt.figure(figsize=(3, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

print(f"Model terbaik: {best_model}")

"""# Save File"""

# Data Clean
df_clean.to_csv("Data_Clean.csv", index=False)

# Data Visualisasi
df_visualisasi.to_csv("Data_to_Visualisasi.csv", index=False)

# Data Model
df_model.to_csv("Data_to_model.csv", index=False)

# Save Model
filename = 'result_model.pkl'
with open(filename, 'wb') as file:
    pickle.dump(best_model, file)